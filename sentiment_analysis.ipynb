{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I43bMheNrinl",
        "outputId": "ea9ead82-07b9-4300-f41b-d341b96f0ce4"
      },
      "outputs": [],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mK68mWhRRJ2K"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoModelForPreTraining"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m7XqNGZ-RMPA"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased', do_lower_case=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JBHj4Vt1RPAJ"
      },
      "outputs": [],
      "source": [
        "from typing import List, Optional, Tuple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hbT1ZS8aRacN"
      },
      "outputs": [],
      "source": [
        "class LIABertClassifier(nn.Module):\n",
        "    def __init__(self,model,num_labels):\n",
        "        super(LIABertClassifier,self).__init__()\n",
        "        self.bert = model.bert\n",
        "        self.config = model.config\n",
        "        self.num_labels = num_labels\n",
        "        self.cls = nn.Linear(self.config.hidden_size,num_labels)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids: Optional[torch.Tensor] = None,\n",
        "        attention_mask: Optional[torch.Tensor] = None,\n",
        "        token_type_ids: Optional[torch.Tensor] = None,\n",
        "        ) ->Tuple[torch.Tensor]:\n",
        "\n",
        "        outputs = self.bert(\n",
        "            input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "        )\n",
        "\n",
        "        sequence_output = outputs[0][:,0,:]\n",
        "        prediction = self.cls(sequence_output)\n",
        "        return prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bq6S_zrpRb8r"
      },
      "outputs": [],
      "source": [
        "model_base= AutoModelForPreTraining.from_pretrained('neuralmind/bert-base-portuguese-cased')\n",
        "model = LIABertClassifier(model=model_base,num_labels=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wlvIlOKKtCPm"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "slnILsqwGxTX"
      },
      "outputs": [],
      "source": [
        "cols = [\"Datetime\",\"Text\",\"Likes\",\"Retweets\",\"Feeling\"]\n",
        "data = pd.read_csv(\n",
        "    r\"C:\\Users\\allan\\Downloads\\drive-download-20230505T001753Z-001\\final.csv\",\n",
        "    header=None,\n",
        "    names=cols,\n",
        "    engine=\"python\",\n",
        "    encoding=\"latin1\",\n",
        "    index_col = False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "REdK4z4YG9kZ"
      },
      "outputs": [],
      "source": [
        "\n",
        "data.drop([\"Datetime\",\"Likes\",\"Retweets\"],\n",
        "          axis=1,\n",
        "          inplace=True)\n",
        "data = data.drop(0)\n",
        "data = data.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-BDbUucftWz_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import re\n",
        "from bs4 import BeautifulSoup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UEyorQS_HArn"
      },
      "outputs": [],
      "source": [
        "def clean_tweet(tweet):\n",
        "    tweet = BeautifulSoup(tweet, \"lxml\").get_text()\n",
        "    tweet = re.sub(r\"@[A-Za-z0-9]+\", ' ', tweet)\n",
        "    tweet = re.sub(r\"https?://[A-Za-z0-9./]+\", ' ', tweet)\n",
        "    tweet = re.sub(r\"[^a-zA-Z.!?']\", ' ', tweet)\n",
        "    tweet = re.sub(r\" +\", ' ', tweet)\n",
        "    return tweet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BlbZpy0HHiV",
        "outputId": "218309a0-e117-47d2-a86c-6090cc41f19e"
      },
      "outputs": [],
      "source": [
        "data_clean = [clean_tweet(tweet) for tweet in data.Text]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H6SOj46BHKEk"
      },
      "outputs": [],
      "source": [
        "data_labels = data.Feeling.values\n",
        "data_labels[data_labels == 'Pos'] = 1\n",
        "data_labels[data_labels == 'Neu'] = 0.5\n",
        "data_labels[data_labels == 'Neg'] = 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nfIXbrL4uppG"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R5Z5ts1gni4V"
      },
      "outputs": [],
      "source": [
        "shuffle=np.random.randint(0,len(data['Text']),1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M95GVXYMUfZ-"
      },
      "outputs": [],
      "source": [
        "ytrain_global = np.array(data['Feeling'].tolist())[shuffle]\n",
        "xtrain_global = np.array(data['Text'])[shuffle]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q78hzrsEvexz",
        "outputId": "b2b65f32-2795-4322-d94f-0e5522feb5dc"
      },
      "outputs": [],
      "source": [
        "xtrain_global[1],ytrain_global[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v0QcffYzjOBO"
      },
      "outputs": [],
      "source": [
        "import sklearn.model_selection as model_selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cGthp7btjrD6"
      },
      "outputs": [],
      "source": [
        "xtrain, xval, ytrain, yval = model_selection.train_test_split(xtrain_global, ytrain_global, test_size=0.30, random_state=42,shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v4KpAFs9jxIu"
      },
      "outputs": [],
      "source": [
        "train_encodings = tokenizer(xtrain.tolist(), truncation=True, padding=True, max_length=512, return_tensors='pt')\n",
        "val_encodings = tokenizer(xval.tolist(), truncation=True, padding=True,max_length=512, return_tensors='pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e0v6SonpkD73"
      },
      "outputs": [],
      "source": [
        "class MyDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
        "        label = torch.tensor(self.labels[idx].astype('float32'))\n",
        "        return (item,label)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-sBluXDxkTzF"
      },
      "outputs": [],
      "source": [
        "ds_train = MyDataset(train_encodings,ytrain)\n",
        "ds_val   = MyDataset(val_encodings,yval)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "myvv1f8KkXhy"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size = 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJ9Wya45kbn1"
      },
      "outputs": [],
      "source": [
        "dl_train = DataLoader(ds_train,shuffle=True,batch_size=batch_size)\n",
        "dl_eval  = DataLoader(ds_val,batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "leLZtyGCkn_z"
      },
      "outputs": [],
      "source": [
        "x,y = next(iter(dl_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oGQo2IYrkcHH"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0cmGNuDlkeA2"
      },
      "outputs": [],
      "source": [
        "batch = {k: v.to(device) for k, v in x.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npVuzTlQkfJ0",
        "outputId": "d1315c30-90a2-484a-facc-e75a499183b8"
      },
      "outputs": [],
      "source": [
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SrkMyjHMkqsY"
      },
      "outputs": [],
      "source": [
        "out = model(**batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uejqQuIfktj_"
      },
      "outputs": [],
      "source": [
        "from torch.optim import AdamW\n",
        "optimizer = AdamW(model.parameters(), lr=5e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SaspM2o0lDcU"
      },
      "outputs": [],
      "source": [
        "num_epochs = 100\n",
        "num_training_steps = num_epochs * len(dl_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nLsiC2emlCjS"
      },
      "outputs": [],
      "source": [
        "from transformers import get_scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QTgVnMM7lD4n"
      },
      "outputs": [],
      "source": [
        "lr_scheduler = get_scheduler(\n",
        "    name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ulFEQmZlGMd"
      },
      "outputs": [],
      "source": [
        "from tqdm.auto import tqdm\n",
        "progress_bar = tqdm(range(num_training_steps))\n",
        "model.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3_1yr5KxlR1f"
      },
      "outputs": [],
      "source": [
        "loss_fct = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YsKQTKQ9lNH7"
      },
      "outputs": [],
      "source": [
        "count = 0\n",
        "for epoch in range(num_epochs):\n",
        "    count+=1\n",
        "    lepochs = []\n",
        "    for batch,y in dl_train:\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        y     = y.to(device)\n",
        "        outputs = model(**batch)\n",
        "        loss = loss_fct(outputs,y.to(torch.long))\n",
        "        lepochs.append(loss.cpu().item())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "    print(np.mean(lepochs))\n",
        "    torch.save(model.state_dict(),f'./model{count}.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CyWQ0fW3lvx0"
      },
      "outputs": [],
      "source": [
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rv3FsDAZlOCO"
      },
      "outputs": [],
      "source": [
        "ytrue = []\n",
        "ypred = []\n",
        "for batch,y in dl_eval:\n",
        "    batch = {k: v.to(device) for k, v in batch.items()}\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**batch)\n",
        "    predictions = torch.argmax(outputs, dim=-1)\n",
        "    ytrue += y.tolist()\n",
        "    ypred += predictions.cpu().tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hB9FdzPgyc6d"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(),'/content/drive/MyDrive/model.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zfZSVbJjzeuV"
      },
      "outputs": [],
      "source": [
        "model.load_state_dict(backup)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "od0wcXeflyXD"
      },
      "outputs": [],
      "source": [
        "from sklearn import metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-UKHK_wUlzi6"
      },
      "outputs": [],
      "source": [
        "metrics.confusion_matrix(ytrue,ypred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u4cSy9ill0n3"
      },
      "outputs": [],
      "source": [
        "print(metrics.classification_report(ytrue,ypred))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
