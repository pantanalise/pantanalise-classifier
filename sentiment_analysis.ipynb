{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I43bMheNrinl",
        "outputId": "ea9ead82-07b9-4300-f41b-d341b96f0ce4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in c:\\python311\\lib\\site-packages (4.28.1)\n",
            "Requirement already satisfied: filelock in c:\\python311\\lib\\site-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in c:\\python311\\lib\\site-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\python311\\lib\\site-packages (from transformers) (1.24.1)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\python311\\lib\\site-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\python311\\lib\\site-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\python311\\lib\\site-packages (from transformers) (2023.5.5)\n",
            "Requirement already satisfied: requests in c:\\python311\\lib\\site-packages (from transformers) (2.28.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\python311\\lib\\site-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in c:\\python311\\lib\\site-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in c:\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: colorama in c:\\python311\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\python311\\lib\\site-packages (from requests->transformers) (2.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\python311\\lib\\site-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\python311\\lib\\site-packages (from requests->transformers) (1.26.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\python311\\lib\\site-packages (from requests->transformers) (2022.9.24)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "mK68mWhRRJ2K"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoModelForPreTraining"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "m7XqNGZ-RMPA"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased', do_lower_case=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "JBHj4Vt1RPAJ"
      },
      "outputs": [],
      "source": [
        "from typing import List, Optional, Tuple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "hbT1ZS8aRacN"
      },
      "outputs": [],
      "source": [
        "class LIABertClassifier(nn.Module):\n",
        "    def __init__(self,model,num_labels):\n",
        "        super(LIABertClassifier,self).__init__()\n",
        "        self.bert = model.bert\n",
        "        self.config = model.config\n",
        "        self.num_labels = num_labels\n",
        "        self.cls = nn.Linear(self.config.hidden_size,num_labels)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids: Optional[torch.Tensor] = None,\n",
        "        attention_mask: Optional[torch.Tensor] = None,\n",
        "        token_type_ids: Optional[torch.Tensor] = None,\n",
        "        ) ->Tuple[torch.Tensor]:\n",
        "\n",
        "        outputs = self.bert(\n",
        "            input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "        )\n",
        "\n",
        "        sequence_output = outputs[0][:,0,:]\n",
        "        prediction = self.cls(sequence_output)\n",
        "        return prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "bq6S_zrpRb8r"
      },
      "outputs": [],
      "source": [
        "model_base= AutoModelForPreTraining.from_pretrained('neuralmind/bert-base-portuguese-cased')\n",
        "model = LIABertClassifier(model=model_base,num_labels=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "wlvIlOKKtCPm"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "slnILsqwGxTX"
      },
      "outputs": [],
      "source": [
        "cols = [\"Datetime\",\"Text\",\"Likes\",\"Retweets\",\"Feeling\"]\n",
        "data = pd.read_csv(\n",
        "    r\"C:\\Users\\allan\\Downloads\\drive-download-20230505T001753Z-001\\final.csv\",\n",
        "    header=None,\n",
        "    names=cols,\n",
        "    engine=\"python\",\n",
        "    encoding=\"utf-8\",\n",
        "    index_col = False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Datetime</th>\n",
              "      <th>Text</th>\n",
              "      <th>Likes</th>\n",
              "      <th>Retweets</th>\n",
              "      <th>Feeling</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Datetime</td>\n",
              "      <td>Text</td>\n",
              "      <td>Likes</td>\n",
              "      <td>Retweets</td>\n",
              "      <td>Feeling</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2022-11-02 23:02:08 UTC+0000</td>\n",
              "      <td>A esquerda pediu o Fora Collor, o Fora FHC, o ...</td>\n",
              "      <td>32871</td>\n",
              "      <td>7123</td>\n",
              "      <td>Pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2022-11-22 14:38:02 UTC+0000</td>\n",
              "      <td>pov: você é a melhor adaptação já feita de um ...</td>\n",
              "      <td>10798</td>\n",
              "      <td>2196</td>\n",
              "      <td>Pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2022-11-02 23:58:42 UTC+0000</td>\n",
              "      <td>odeio gente grudenta, mas se o grudento for el...</td>\n",
              "      <td>8265</td>\n",
              "      <td>2084</td>\n",
              "      <td>Pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2022-11-21 03:45:18 UTC+0000</td>\n",
              "      <td>rbd me leva de volta a melhor parte da minha v...</td>\n",
              "      <td>2022</td>\n",
              "      <td>396</td>\n",
              "      <td>Pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2135</th>\n",
              "      <td>2022-11-02 23:13:14 UTC+0000</td>\n",
              "      <td>Dica da noite\\n\\nÁRIES: esqueça o passado\\nTOU...</td>\n",
              "      <td>3421</td>\n",
              "      <td>198</td>\n",
              "      <td>Neu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2136</th>\n",
              "      <td>2022-11-10 14:33:52 UTC+0000</td>\n",
              "      <td>A vida é sobre fazer sua parte. Você não contr...</td>\n",
              "      <td>4892</td>\n",
              "      <td>2367</td>\n",
              "      <td>Neu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2137</th>\n",
              "      <td>2023-02-13 22:16:33 UTC+0000</td>\n",
              "      <td>Bella Ramsey falou sobre a ajuda que teve de P...</td>\n",
              "      <td>4095</td>\n",
              "      <td>398</td>\n",
              "      <td>Neu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2138</th>\n",
              "      <td>2022-11-02 23:03:46 UTC+0000</td>\n",
              "      <td>Há alguma chance de vocês perdoar Bolsonaro?</td>\n",
              "      <td>3662</td>\n",
              "      <td>347</td>\n",
              "      <td>Neu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2139</th>\n",
              "      <td>2022-11-02 20:56:13 UTC+0000</td>\n",
              "      <td>Clube de regatas do Flamengo em nevou 👨‍🦳 http...</td>\n",
              "      <td>1894</td>\n",
              "      <td>211</td>\n",
              "      <td>Neu</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2140 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                          Datetime  \\\n",
              "0                         Datetime   \n",
              "1     2022-11-02 23:02:08 UTC+0000   \n",
              "2     2022-11-22 14:38:02 UTC+0000   \n",
              "3     2022-11-02 23:58:42 UTC+0000   \n",
              "4     2022-11-21 03:45:18 UTC+0000   \n",
              "...                            ...   \n",
              "2135  2022-11-02 23:13:14 UTC+0000   \n",
              "2136  2022-11-10 14:33:52 UTC+0000   \n",
              "2137  2023-02-13 22:16:33 UTC+0000   \n",
              "2138  2022-11-02 23:03:46 UTC+0000   \n",
              "2139  2022-11-02 20:56:13 UTC+0000   \n",
              "\n",
              "                                                   Text  Likes  Retweets  \\\n",
              "0                                                  Text  Likes  Retweets   \n",
              "1     A esquerda pediu o Fora Collor, o Fora FHC, o ...  32871      7123   \n",
              "2     pov: você é a melhor adaptação já feita de um ...  10798      2196   \n",
              "3     odeio gente grudenta, mas se o grudento for el...   8265      2084   \n",
              "4     rbd me leva de volta a melhor parte da minha v...   2022       396   \n",
              "...                                                 ...    ...       ...   \n",
              "2135  Dica da noite\\n\\nÁRIES: esqueça o passado\\nTOU...   3421       198   \n",
              "2136  A vida é sobre fazer sua parte. Você não contr...   4892      2367   \n",
              "2137  Bella Ramsey falou sobre a ajuda que teve de P...   4095       398   \n",
              "2138       Há alguma chance de vocês perdoar Bolsonaro?   3662       347   \n",
              "2139  Clube de regatas do Flamengo em nevou 👨‍🦳 http...   1894       211   \n",
              "\n",
              "      Feeling  \n",
              "0     Feeling  \n",
              "1         Pos  \n",
              "2         Pos  \n",
              "3         Pos  \n",
              "4         Pos  \n",
              "...       ...  \n",
              "2135      Neu  \n",
              "2136      Neu  \n",
              "2137      Neu  \n",
              "2138      Neu  \n",
              "2139      Neu  \n",
              "\n",
              "[2140 rows x 5 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "REdK4z4YG9kZ"
      },
      "outputs": [],
      "source": [
        "\n",
        "data.drop([\"Datetime\",\"Likes\",\"Retweets\"],\n",
        "          axis=1,\n",
        "          inplace=True)\n",
        "data = data.drop(0)\n",
        "data = data.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ekphrasis in c:\\users\\allan\\appdata\\roaming\\python\\python311\\site-packages (0.5.4)\n",
            "Requirement already satisfied: termcolor in c:\\python311\\lib\\site-packages (from ekphrasis) (2.3.0)\n",
            "Requirement already satisfied: tqdm in c:\\python311\\lib\\site-packages (from ekphrasis) (4.65.0)\n",
            "Requirement already satisfied: colorama in c:\\python311\\lib\\site-packages (from ekphrasis) (0.4.6)\n",
            "Requirement already satisfied: ujson in c:\\python311\\lib\\site-packages (from ekphrasis) (5.7.0)\n",
            "Requirement already satisfied: matplotlib in c:\\users\\allan\\appdata\\roaming\\python\\python311\\site-packages (from ekphrasis) (3.7.1)\n",
            "Requirement already satisfied: nltk in c:\\users\\allan\\appdata\\roaming\\python\\python311\\site-packages (from ekphrasis) (3.8.1)\n",
            "Requirement already satisfied: ftfy in c:\\python311\\lib\\site-packages (from ekphrasis) (6.1.1)\n",
            "Requirement already satisfied: numpy in c:\\python311\\lib\\site-packages (from ekphrasis) (1.24.1)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in c:\\users\\allan\\appdata\\roaming\\python\\python311\\site-packages (from ftfy->ekphrasis) (0.2.6)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\allan\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib->ekphrasis) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\allan\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib->ekphrasis) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\python311\\lib\\site-packages (from matplotlib->ekphrasis) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\python311\\lib\\site-packages (from matplotlib->ekphrasis) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\python311\\lib\\site-packages (from matplotlib->ekphrasis) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in c:\\python311\\lib\\site-packages (from matplotlib->ekphrasis) (9.5.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\python311\\lib\\site-packages (from matplotlib->ekphrasis) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\python311\\lib\\site-packages (from matplotlib->ekphrasis) (2.8.2)\n",
            "Requirement already satisfied: click in c:\\users\\allan\\appdata\\roaming\\python\\python311\\site-packages (from nltk->ekphrasis) (8.1.3)\n",
            "Requirement already satisfied: joblib in c:\\python311\\lib\\site-packages (from nltk->ekphrasis) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in c:\\python311\\lib\\site-packages (from nltk->ekphrasis) (2023.5.5)\n",
            "Requirement already satisfied: six>=1.5 in c:\\python311\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->ekphrasis) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install ekphrasis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ekphrasis.classes.preprocessor import TextPreProcessor\n",
        "from ekphrasis.dicts.emoticons import emoticons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading twitter - 1grams ...\n",
            "Reading twitter - 2grams ...\n",
            "Reading twitter - 1grams ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\allan\\AppData\\Roaming\\Python\\Python311\\site-packages\\ekphrasis\\classes\\exmanager.py:14: FutureWarning: Possible nested set at position 42\n",
            "  regexes = {k.lower(): re.compile(self.expressions[k]) for k, v in\n"
          ]
        }
      ],
      "source": [
        "text_processor = TextPreProcessor(\n",
        "    \n",
        "    # terms that will be normalized\n",
        "    normalize=['url', 'email', 'percent', 'money', 'phone', 'user',\n",
        "        'time', 'url', 'date', 'number'],\n",
        "    \n",
        "    # terms that will be annotated\n",
        "    annotate={\"hashtag\", \"allcaps\", \"elongated\", \"repeated\",\n",
        "        'emphasis', 'censored'},\n",
        "    \n",
        "    fix_html=True,  # fix HTML tokens\n",
        "    \n",
        "    # corpus from which the word statistics are going to be used \n",
        "    # for word segmentation \n",
        "    segmenter=\"twitter\", \n",
        "    \n",
        "    # corpus from which the word statistics are going to be used \n",
        "    # for spell correction\n",
        "    corrector=\"twitter\", \n",
        "    \n",
        "    unpack_hashtags=True,  # perform word segmentation on hashtags\n",
        "    unpack_contractions=True,  # Unpack contractions (can't -> can not)\n",
        "    spell_correct_elong=False,  # spell correction for elongated words\n",
        "    \n",
        "    # select a tokenizer. You can use SocialTokenizer, or pass your own\n",
        "    # the tokenizer, should take as input a string and return a list of tokens\n",
        "    # tokenizer=tokenizer.tokenize,\n",
        "    \n",
        "    # list of dictionaries, for replacing tokens extracted from the text,\n",
        "    # with other expressions. You can pass more than one dictionaries.\n",
        "    dicts=[emoticons]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "pattern = r\"<.*?>\" #pattern used by ekphrasis to mark social network lingo\n",
        "\n",
        "#function that only tokenizes what is not from the ekphrasis pattern\n",
        "#this nedded to be done so we could use the portuguese tokenizer and keep\n",
        "#all the ekphrasis tags\n",
        "def ekphrasis_tokenize(text):\n",
        "    \n",
        "    ptext = text_processor.pre_process_doc(text)\n",
        "    \n",
        "    pattern_matches = re.findall(pattern, ptext)\n",
        "    \n",
        "    tokens = []\n",
        "    prev_end = 0\n",
        "    for match in pattern_matches:\n",
        "        start, end = re.search(re.escape(match), ptext).span()\n",
        "        tokens.extend(tokenizer.tokenize(ptext[prev_end:start]))\n",
        "        tokens.append(match)\n",
        "        prev_end = end\n",
        "    tokens.extend(tokenizer.tokenize(ptext[prev_end:]))\n",
        "    \n",
        "    return tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BlbZpy0HHiV",
        "outputId": "218309a0-e117-47d2-a86c-6090cc41f19e"
      },
      "outputs": [],
      "source": [
        "data_clean = data.copy()\n",
        "data_clean.Text = [ekphrasis_tokenize(tweet) for tweet in data.Text]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "H6SOj46BHKEk"
      },
      "outputs": [],
      "source": [
        "data_labels = data_clean.Feeling.values\n",
        "data_labels[data_labels == 'Pos'] = 1\n",
        "data_labels[data_labels == 'Neu'] = 0.5\n",
        "data_labels[data_labels == 'Neg'] = 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Feeling</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[A, esquerda, pediu, o, Fora, Collor, ,, o, Fo...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[po, ##v, :, você, é, a, melhor, adaptação, já...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[o, ##de, ##io, gente, gru, ##dent, ##a, ,, ma...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[r, ##b, ##d, me, leva, de, volta, a, melhor, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[Feliz, aniversário, para, a, talentos, ##íssi...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2134</th>\n",
              "      <td>[Di, ##ca, da, noite, Á, ##RI, ##ES, :, esque,...</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2135</th>\n",
              "      <td>[A, vida, é, sobre, fazer, sua, parte, ., Você...</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2136</th>\n",
              "      <td>[Bella, Ram, ##sey, falou, sobre, a, ajuda, qu...</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2137</th>\n",
              "      <td>[Há, alguma, chance, de, você, ##s, perdo, ##a...</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2138</th>\n",
              "      <td>[Clube, de, reg, ##atas, do, Flamengo, em, ne,...</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2139 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   Text Feeling\n",
              "0     [A, esquerda, pediu, o, Fora, Collor, ,, o, Fo...       1\n",
              "1     [po, ##v, :, você, é, a, melhor, adaptação, já...       1\n",
              "2     [o, ##de, ##io, gente, gru, ##dent, ##a, ,, ma...       1\n",
              "3     [r, ##b, ##d, me, leva, de, volta, a, melhor, ...       1\n",
              "4     [Feliz, aniversário, para, a, talentos, ##íssi...       1\n",
              "...                                                 ...     ...\n",
              "2134  [Di, ##ca, da, noite, Á, ##RI, ##ES, :, esque,...     0.5\n",
              "2135  [A, vida, é, sobre, fazer, sua, parte, ., Você...     0.5\n",
              "2136  [Bella, Ram, ##sey, falou, sobre, a, ajuda, qu...     0.5\n",
              "2137  [Há, alguma, chance, de, você, ##s, perdo, ##a...     0.5\n",
              "2138  [Clube, de, reg, ##atas, do, Flamengo, em, ne,...     0.5\n",
              "\n",
              "[2139 rows x 2 columns]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_clean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "nfIXbrL4uppG"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "R5Z5ts1gni4V"
      },
      "outputs": [],
      "source": [
        "shuffle=np.random.randint(0,len(data_clean['Text']),1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "M95GVXYMUfZ-"
      },
      "outputs": [],
      "source": [
        "ytrain_global = np.array(data_clean['Feeling'].tolist())[shuffle]\n",
        "xtrain_global = np.array(data_clean['Text'])[shuffle]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q78hzrsEvexz",
        "outputId": "b2b65f32-2795-4322-d94f-0e5522feb5dc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(['Inglaterra',\n",
              "  'não',\n",
              "  'é',\n",
              "  'ra',\n",
              "  '##cista',\n",
              "  '<allcaps>',\n",
              "  'K',\n",
              "  '<elongated>',\n",
              "  '</allcaps>',\n",
              "  'só',\n",
              "  'invadiram',\n",
              "  'metade',\n",
              "  'do',\n",
              "  'globo',\n",
              "  'promovendo',\n",
              "  'geno',\n",
              "  '##c',\n",
              "  '##ídio',\n",
              "  ',',\n",
              "  'apar',\n",
              "  '##the',\n",
              "  '##id',\n",
              "  ',',\n",
              "  'etno',\n",
              "  '##c',\n",
              "  '##ídio',\n",
              "  'mas',\n",
              "  'não',\n",
              "  'são',\n",
              "  'ra',\n",
              "  '##cista',\n",
              "  '##s',\n",
              "  'não',\n",
              "  ',',\n",
              "  'confia',\n",
              "  'Não',\n",
              "  'são',\n",
              "  'homo',\n",
              "  '##f',\n",
              "  '##ób',\n",
              "  '##icos',\n",
              "  ',',\n",
              "  'Alan',\n",
              "  'Turing',\n",
              "  'foi',\n",
              "  'na',\n",
              "  'verdade',\n",
              "  'um',\n",
              "  'ho',\n",
              "  '##log',\n",
              "  '##rama',\n",
              "  'e',\n",
              "  'não',\n",
              "  'um',\n",
              "  'ser',\n",
              "  'humano',\n",
              "  'vítima',\n",
              "  'de',\n",
              "  'cas',\n",
              "  '##tração',\n",
              "  'química',\n",
              "  'por',\n",
              "  'ser',\n",
              "  'gay'],\n",
              " 0.0)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "xtrain_global[12],ytrain_global[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v0QcffYzjOBO"
      },
      "outputs": [],
      "source": [
        "import sklearn.model_selection as model_selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cGthp7btjrD6"
      },
      "outputs": [],
      "source": [
        "xtrain, xval, ytrain, yval = model_selection.train_test_split(xtrain_global, ytrain_global, test_size=0.30, random_state=42,shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v4KpAFs9jxIu"
      },
      "outputs": [],
      "source": [
        "train_encodings = tokenizer(xtrain.tolist(), truncation=True, padding=True, max_length=512, return_tensors='pt')\n",
        "val_encodings = tokenizer(xval.tolist(), truncation=True, padding=True,max_length=512, return_tensors='pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e0v6SonpkD73"
      },
      "outputs": [],
      "source": [
        "class MyDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
        "        label = torch.tensor(self.labels[idx].astype('float32'))\n",
        "        return (item,label)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-sBluXDxkTzF"
      },
      "outputs": [],
      "source": [
        "ds_train = MyDataset(train_encodings,ytrain)\n",
        "ds_val   = MyDataset(val_encodings,yval)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "myvv1f8KkXhy"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size = 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJ9Wya45kbn1"
      },
      "outputs": [],
      "source": [
        "dl_train = DataLoader(ds_train,shuffle=True,batch_size=batch_size)\n",
        "dl_eval  = DataLoader(ds_val,batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "leLZtyGCkn_z"
      },
      "outputs": [],
      "source": [
        "x,y = next(iter(dl_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oGQo2IYrkcHH"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0cmGNuDlkeA2"
      },
      "outputs": [],
      "source": [
        "batch = {k: v.to(device) for k, v in x.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npVuzTlQkfJ0",
        "outputId": "d1315c30-90a2-484a-facc-e75a499183b8"
      },
      "outputs": [],
      "source": [
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SrkMyjHMkqsY"
      },
      "outputs": [],
      "source": [
        "out = model(**batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uejqQuIfktj_"
      },
      "outputs": [],
      "source": [
        "from torch.optim import AdamW\n",
        "optimizer = AdamW(model.parameters(), lr=5e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SaspM2o0lDcU"
      },
      "outputs": [],
      "source": [
        "num_epochs = 100\n",
        "num_training_steps = num_epochs * len(dl_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nLsiC2emlCjS"
      },
      "outputs": [],
      "source": [
        "from transformers import get_scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QTgVnMM7lD4n"
      },
      "outputs": [],
      "source": [
        "lr_scheduler = get_scheduler(\n",
        "    name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ulFEQmZlGMd"
      },
      "outputs": [],
      "source": [
        "from tqdm.auto import tqdm\n",
        "progress_bar = tqdm(range(num_training_steps))\n",
        "model.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3_1yr5KxlR1f"
      },
      "outputs": [],
      "source": [
        "loss_fct = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YsKQTKQ9lNH7"
      },
      "outputs": [],
      "source": [
        "count = 0\n",
        "for epoch in range(num_epochs):\n",
        "    count+=1\n",
        "    lepochs = []\n",
        "    for batch,y in dl_train:\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        y     = y.to(device)\n",
        "        outputs = model(**batch)\n",
        "        loss = loss_fct(outputs,y.to(torch.long))\n",
        "        lepochs.append(loss.cpu().item())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "    print(np.mean(lepochs))\n",
        "    torch.save(model.state_dict(),f'./model{count}.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CyWQ0fW3lvx0"
      },
      "outputs": [],
      "source": [
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rv3FsDAZlOCO"
      },
      "outputs": [],
      "source": [
        "ytrue = []\n",
        "ypred = []\n",
        "for batch,y in dl_eval:\n",
        "    batch = {k: v.to(device) for k, v in batch.items()}\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**batch)\n",
        "    predictions = torch.argmax(outputs, dim=-1)\n",
        "    ytrue += y.tolist()\n",
        "    ypred += predictions.cpu().tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hB9FdzPgyc6d"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(),'/content/drive/MyDrive/model.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zfZSVbJjzeuV"
      },
      "outputs": [],
      "source": [
        "model.load_state_dict(backup)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "od0wcXeflyXD"
      },
      "outputs": [],
      "source": [
        "from sklearn import metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-UKHK_wUlzi6"
      },
      "outputs": [],
      "source": [
        "metrics.confusion_matrix(ytrue,ypred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u4cSy9ill0n3"
      },
      "outputs": [],
      "source": [
        "print(metrics.classification_report(ytrue,ypred))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
